{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4774361b-0aaa-46bf-8907-82c87ed783f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 309 entries, 0 to 308\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count  Dtype\n",
      "---  ------                 --------------  -----\n",
      " 0   Unnamed: 0             309 non-null    int64\n",
      " 1   GENDER                 309 non-null    int64\n",
      " 2   AGE                    309 non-null    int64\n",
      " 3   SMOKING                309 non-null    int64\n",
      " 4   YELLOW_FINGERS         309 non-null    int64\n",
      " 5   ANXIETY                309 non-null    int64\n",
      " 6   PEER_PRESSURE          309 non-null    int64\n",
      " 7   CHRONIC DISEASE        309 non-null    int64\n",
      " 8   FATIGUE                309 non-null    int64\n",
      " 9   ALLERGY                309 non-null    int64\n",
      " 10  WHEEZING               309 non-null    int64\n",
      " 11  ALCOHOL CONSUMING      309 non-null    int64\n",
      " 12  COUGHING               309 non-null    int64\n",
      " 13  SHORTNESS OF BREATH    309 non-null    int64\n",
      " 14  SWALLOWING DIFFICULTY  309 non-null    int64\n",
      " 15  CHEST PAIN             309 non-null    int64\n",
      " 16  LUNG_CANCER            309 non-null    int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 41.2 KB\n",
      "None\n",
      "   Unnamed: 0  GENDER  AGE  SMOKING  YELLOW_FINGERS  ANXIETY  PEER_PRESSURE  \\\n",
      "0           0       1   69        1               2        2              1   \n",
      "1           1       1   74        2               1        1              1   \n",
      "2           2       0   59        1               1        1              2   \n",
      "3           3       1   63        2               2        2              1   \n",
      "4           4       0   63        1               2        1              1   \n",
      "\n",
      "   CHRONIC DISEASE  FATIGUE   ALLERGY   WHEEZING  ALCOHOL CONSUMING  COUGHING  \\\n",
      "0                1         2         1         2                  2         2   \n",
      "1                2         2         2         1                  1         1   \n",
      "2                1         2         1         2                  1         2   \n",
      "3                1         1         1         1                  2         1   \n",
      "4                1         1         1         2                  1         2   \n",
      "\n",
      "   SHORTNESS OF BREATH  SWALLOWING DIFFICULTY  CHEST PAIN  LUNG_CANCER  \n",
      "0                    2                      2           2            1  \n",
      "1                    2                      2           2            1  \n",
      "2                    2                      1           2            0  \n",
      "3                    1                      2           2            0  \n",
      "4                    2                      1           1            0  \n",
      "Unnamed: 0               0\n",
      "GENDER                   0\n",
      "AGE                      0\n",
      "SMOKING                  0\n",
      "YELLOW_FINGERS           0\n",
      "ANXIETY                  0\n",
      "PEER_PRESSURE            0\n",
      "CHRONIC DISEASE          0\n",
      "FATIGUE                  0\n",
      "ALLERGY                  0\n",
      "WHEEZING                 0\n",
      "ALCOHOL CONSUMING        0\n",
      "COUGHING                 0\n",
      "SHORTNESS OF BREATH      0\n",
      "SWALLOWING DIFFICULTY    0\n",
      "CHEST PAIN               0\n",
      "LUNG_CANCER              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Users\\LENOVO\\OneDrive\\AICTE\\AI Medical Diagnosis System\\Dataset Text Based\\prepocessed_lungs_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb443385-2b5c-4e02-a119-1edca02a5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'GENDER', 'AGE', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY',\n",
      "       'PEER_PRESSURE', 'CHRONIC DISEASE', 'FATIGUE ', 'ALLERGY ', 'WHEEZING',\n",
      "       'ALCOHOL CONSUMING', 'COUGHING', 'SHORTNESS OF BREATH',\n",
      "       'SWALLOWING DIFFICULTY', 'CHEST PAIN', 'LUNG_CANCER'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ccedd0-dfad-48fc-bce7-c7c45ee4f790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Preprocessing Complete!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Specify the target column\n",
    "target_col = \"SWALLOWING DIFFICULTY\"\n",
    "\n",
    "# Handle missing values using median imputation\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[df.columns] = imputer.fit_transform(df)\n",
    "\n",
    "# Identify categorical columns (excluding the target)\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "if target_col in cat_cols:\n",
    "    cat_cols.remove(target_col)\n",
    "\n",
    "# Encode categorical columns\n",
    "if cat_cols:\n",
    "    encoder = OrdinalEncoder()\n",
    "    df[cat_cols] = encoder.fit_transform(df[cat_cols])\n",
    "\n",
    "# Encode the target column\n",
    "target_encoder = LabelEncoder()\n",
    "df[target_col] = target_encoder.fit_transform(df[target_col])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Standardize only numerical features\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "# Convert back to DataFrame (optional)\n",
    "X = pd.DataFrame(X, columns=df.drop(columns=[target_col]).columns)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"✅ Data Preprocessing Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c09a1b8f-d63e-4854-bad0-446e904088ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Accuracy: 0.8226\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85        33\n",
      "           1       0.88      0.72      0.79        29\n",
      "\n",
      "    accuracy                           0.82        62\n",
      "   macro avg       0.83      0.82      0.82        62\n",
      "weighted avg       0.83      0.82      0.82        62\n",
      "\n",
      "\n",
      "CatBoost Accuracy: 0.9032\n",
      "CatBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        33\n",
      "           1       0.96      0.83      0.89        29\n",
      "\n",
      "    accuracy                           0.90        62\n",
      "   macro avg       0.91      0.90      0.90        62\n",
      "weighted avg       0.91      0.90      0.90        62\n",
      "\n",
      "\n",
      "Gradient Boosting Accuracy: 0.8387\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86        33\n",
      "           1       0.88      0.76      0.81        29\n",
      "\n",
      "    accuracy                           0.84        62\n",
      "   macro avg       0.85      0.83      0.84        62\n",
      "weighted avg       0.84      0.84      0.84        62\n",
      "\n",
      "\n",
      "Random Forest Accuracy: 0.9032\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        33\n",
      "           1       0.93      0.86      0.89        29\n",
      "\n",
      "    accuracy                           0.90        62\n",
      "   macro avg       0.91      0.90      0.90        62\n",
      "weighted avg       0.90      0.90      0.90        62\n",
      "\n",
      "\n",
      "✅ Data Preprocessing & Model Training Complete!\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load Dataset (Ensure df is available)\n",
    "try:\n",
    "    df  # Check if df is already loaded\n",
    "except NameError:\n",
    "    raise ValueError(\"Dataset 'df' is not defined. Load your dataset before running this code.\")\n",
    "\n",
    "# Clean Column Names (Fix JSON Errors in CatBoost)\n",
    "df.columns = df.columns.str.replace(r\"[^a-zA-Z0-9_]\", \"_\", regex=True)\n",
    "\n",
    "# Specify Target Columns\n",
    "target_cols = [\"SWALLOWING_DIFFICULTY\", \"YELLOW_FINGERS\"]  # Adjust as per dataset\n",
    "\n",
    "# Handle Missing Values (Median Imputation)\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[df.columns] = imputer.fit_transform(df)\n",
    "\n",
    "# Identify Categorical Columns (excluding target columns)\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "cat_cols = [col for col in cat_cols if col not in target_cols]\n",
    "\n",
    "# Encode Categorical Features\n",
    "if cat_cols:\n",
    "    encoder = OrdinalEncoder()\n",
    "    df[cat_cols] = encoder.fit_transform(df[cat_cols])\n",
    "\n",
    "# Encode Target Columns\n",
    "label_encoders = {}\n",
    "for target_col in target_cols:\n",
    "    label_encoders[target_col] = LabelEncoder()\n",
    "    df[target_col] = label_encoders[target_col].fit_transform(df[target_col])\n",
    "\n",
    "# Separate Features and Targets\n",
    "X = df.drop(columns=target_cols)\n",
    "y = df[target_cols]  # Multi-label classification\n",
    "\n",
    "# Standardize Only Numerical Features\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "# Convert Back to DataFrame\n",
    "X = pd.DataFrame(X, columns=df.drop(columns=target_cols).columns)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y[target_cols[0]], test_size=0.2, random_state=42, stratify=y[target_cols[0]])\n",
    "\n",
    "# Train Models (Without LGBM)\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42),  # Removed use_label_encoder\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "# Train & Evaluate Each Model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"{name} Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "print(\"\\n✅ Data Preprocessing & Model Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f54d66-6f64-4496-8eb7-9bc4eef6ed51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116, number of negative: 131\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154\n",
      "[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.469636 -> initscore=-0.121607\n",
      "[LightGBM] [Info] Start training from score -0.121607\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model saved as Lungs_model.sav\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "\n",
    "# Train the model (example)\n",
    "best_lgbm = LGBMClassifier()\n",
    "best_lgbm.fit(X_train, y_train)  # Ensure X_train and y_train are defined\n",
    "\n",
    "# Save the trained model\n",
    "model_filename = \"Lungs_model.sav\"\n",
    "joblib.dump(best_lgbm, model_filename)\n",
    "print(f\"Model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed3615-c022-4b35-8b3e-a082e2fee2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
